{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyunt7/ODL-Assignment/blob/david_branch/david_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQQTLvwsmawV"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import matplotlib.colors\n",
        "import matplotlib.ticker as mtick\n",
        "\n",
        "# feature selection\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_regression, f_classif, chi2\n",
        "\n",
        "# feature scaler\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "\n",
        "# for fixing the imbalanced dataset and split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp-1wpVaC-y7"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GACOSM5amgQe"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtCMoUrz8k6F"
      },
      "outputs": [],
      "source": [
        "for name in df.columns:\n",
        "    df[name] = df[name].astype(int)\n",
        "    # print(name , df[name].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSs8YPiNVEWW"
      },
      "outputs": [],
      "source": [
        "#Drop duplications in dataframe\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5hgIcmX0ChT",
        "outputId": "c6dd1532-9c91-4e19-b41d-c176111cf3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 229474 entries, 0 to 253679\n",
            "Data columns (total 18 columns):\n",
            " #   Column                Non-Null Count   Dtype\n",
            "---  ------                --------------   -----\n",
            " 0   Diabetes_binary       229474 non-null  int64\n",
            " 1   HighBP                229474 non-null  int64\n",
            " 2   HighChol              229474 non-null  int64\n",
            " 3   CholCheck             229474 non-null  int64\n",
            " 4   BMI                   229474 non-null  int64\n",
            " 5   Smoker                229474 non-null  int64\n",
            " 6   Stroke                229474 non-null  int64\n",
            " 7   HeartDiseaseorAttack  229474 non-null  int64\n",
            " 8   PhysActivity          229474 non-null  int64\n",
            " 9   Fruits                229474 non-null  int64\n",
            " 10  Veggies               229474 non-null  int64\n",
            " 11  HvyAlcoholConsump     229474 non-null  int64\n",
            " 12  GenHlth               229474 non-null  int64\n",
            " 13  MentHlth              229474 non-null  int64\n",
            " 14  PhysHlth              229474 non-null  int64\n",
            " 15  DiffWalk              229474 non-null  int64\n",
            " 16  Age                   229474 non-null  int64\n",
            " 17  Income                229474 non-null  int64\n",
            "dtypes: int64(18)\n",
            "memory usage: 33.3 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7amUww6Ux-h"
      },
      "outputs": [],
      "source": [
        "# drop column\n",
        "df = df.drop(['AnyHealthcare','Education'], axis=1);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIZ42H6cQdiq"
      },
      "outputs": [],
      "source": [
        "# grouped variables\n",
        "target = 'Diabetes_binary'\n",
        "bool_vars = (df.nunique()[df.nunique() == 2]\n",
        "                .index\n",
        "                .drop(labels='Diabetes_binary'))\n",
        "num_vars = [var for var in df.columns if var not in bool_vars and var != 'Diabetes_binary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "fSwTiG1VQwZx",
        "outputId": "9ac0b9e2-6fe3-4d15-d333-9fed676422a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1     35097\n",
            "0    194377\n",
            "Name: Diabetes_binary, dtype: int64\n",
            "1    15.294543%\n",
            "0    84.705457%\n",
            "Name: Diabetes_binary, dtype: object\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(df['Diabetes_binary'].value_counts(ascending=True))\n",
        "print(df['Diabetes_binary'].value_counts(1,ascending=True).apply(lambda x: format(x, '%')))\n",
        "print()\n",
        "df['Diabetes_binary'].value_counts(1).plot(kind='barh',figsize=(10, 2)).spines[['top', 'right']].set_visible(False);\n",
        "plt.title('Diabetes_binary Distribution (%)', fontsize=18)\n",
        "plt.yticks(ticks=[0,1], labels=['Non-Diabetic', 'Diabetic']);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Over, under sampling"
      ],
      "metadata": {
        "id": "ek3hcEdYOOmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shuNoWEZTrPG"
      },
      "outputs": [],
      "source": [
        "# from sklearn.utils import resample\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = df[df.Diabetes_binary == 0]\n",
        "df_minority = df[df.Diabetes_binary == 1]\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,\n",
        "                                   n_samples=45000,\n",
        "                                   random_state=123)\n",
        "\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Split features (X) and target (y) variables\n",
        "X = df_downsampled.drop('Diabetes_binary', axis=1)\n",
        "y = df_downsampled['Diabetes_binary']\n",
        "\n",
        "# Perform oversampling using SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=123)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Perform undersampling using RandomUnderSampler\n",
        "under_sampler = RandomUnderSampler(sampling_strategy='auto', random_state=123)\n",
        "X_resampled, y_resampled = under_sampler.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "# Convert oversampled and undersampled data back to DataFrame\n",
        "df_downsampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "df_downsampled['Diabetes_binary'] = y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsFnhkuLTeso"
      },
      "outputs": [],
      "source": [
        "print(df_downsampled['Diabetes_binary'].value_counts(ascending=True))\n",
        "print(df_downsampled['Diabetes_binary'].value_counts(1,ascending=True).apply(lambda x: format(x, '%')))\n",
        "print()\n",
        "df_downsampled['Diabetes_binary'].value_counts(1).plot(kind='barh',figsize=(10, 2)).spines[['top', 'right']].set_visible(False);\n",
        "plt.title('Diabetes_binary Distribution (%)', fontsize=18)\n",
        "plt.yticks(ticks=[0,1], labels=['Non-Diabetic', 'Diabetic']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15CIKjDSoaDW",
        "outputId": "4f8bf256-db10-4318-c52e-4e52d5b02ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 70194 entries, 82692 to 253679\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype\n",
            "---  ------                --------------  -----\n",
            " 0   Diabetes_binary       70194 non-null  int64\n",
            " 1   HighBP                70194 non-null  int64\n",
            " 2   HighChol              70194 non-null  int64\n",
            " 3   CholCheck             70194 non-null  int64\n",
            " 4   BMI                   70194 non-null  int64\n",
            " 5   HeartDiseaseorAttack  70194 non-null  int64\n",
            " 6   PhysActivity          70194 non-null  int64\n",
            " 7   GenHlth               70194 non-null  int64\n",
            " 8   DiffWalk              70194 non-null  int64\n",
            " 9   Age                   70194 non-null  int64\n",
            " 10  Income                70194 non-null  int64\n",
            "dtypes: int64(11)\n",
            "memory usage: 6.4 MB\n"
          ]
        }
      ],
      "source": [
        "df_downsampled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_7TzjcAAUl_"
      },
      "outputs": [],
      "source": [
        "# bmi (bar chart)\n",
        "def tranform_bmi(x):\n",
        "    if x < 18.5 :\n",
        "        return 1\n",
        "    elif 18.5 <= x <= 24.9 :\n",
        "        return 2\n",
        "    elif 25 <= x <= 29.9 :\n",
        "        return 3\n",
        "    else:\n",
        "        return 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQEYVhAJLOmP"
      },
      "outputs": [],
      "source": [
        "df_downsampled['BMI_bins'] = df_downsampled[\"BMI\"].apply(tranform_bmi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqJ5Q1pzXe6a"
      },
      "outputs": [],
      "source": [
        "del df_downsampled[\"BMI\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP_TY01yoowF"
      },
      "source": [
        "Ma Codes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFF-cEObI56k",
        "outputId": "a1ff87ef-e12d-4d1e-cc93-504d10d72776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/176.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYAo2hp2oqgh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import normalize\n",
        "import keras_tuner as kt\n",
        "from keras.layers import LSTM, Dense, Dropout,  BatchNormalization, Activation\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import keras\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD7Ivn4opFGB"
      },
      "outputs": [],
      "source": [
        "X = df_downsampled.iloc[:, 1:].values\n",
        "y = df_downsampled.iloc[:, 0].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwpJ9qjOpeKi"
      },
      "outputs": [],
      "source": [
        "X = normalize(X, axis=0)\n",
        "# X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
        "# X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "# X = (X - np.median(X, axis=0)) / (np.percentile(X, 75, axis=0) - np.percentile(X, 25, axis=0))\n",
        "# X = X / np.linalg.norm(X, ord=2, axis=1, keepdims=True)\n",
        "# X = np.log(X + 1)  # Adding 1 to avoid logarithm of zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBFisCzasxmc"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxOrGqipsxSY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have your original data in a NumPy array 'X'\n",
        "# And the scaled data after Min-Max scaling in 'X_scaled'\n",
        "\n",
        "# Randomly sample 100 data points from 'X' and 'X_scaled'\n",
        "num_samples_to_plot = 100\n",
        "sample_indices = np.random.choice(len(X), num_samples_to_plot, replace=False)\n",
        "feature_indices = np.arange(1, 20)\n",
        "\n",
        "# Set up the figure and subplots\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot the original data with blue lines for the sampled data\n",
        "ax.plot(feature_indices, X[sample_indices].T, 'b-', alpha=0.5, label='Original Data (Sampled)')\n",
        "\n",
        "# Plot the scaled data with red lines for the sampled data\n",
        "ax.plot(feature_indices, X_scaled[sample_indices].T, 'r-', alpha=0.5, label='Scaled Data (Min-Max, Sampled)')\n",
        "\n",
        "# Set plot title and labels\n",
        "ax.set_title('Comparison Before and After Unit Vector Scaling (Sampled)')\n",
        "ax.set_xlabel('Feature Index')\n",
        "ax.set_ylabel('Feature Values')\n",
        "\n",
        "# No legend, comment out or remove the following line:\n",
        "# ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZUckmkKp8-z"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change 2D to 3D, adding sequence"
      ],
      "metadata": {
        "id": "ocU9FnsYOUwY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYutseuzqD5T"
      },
      "outputs": [],
      "source": [
        "sequence_length = 1\n",
        "X_train_seq = X_train[:, np.newaxis, :]\n",
        "X_test_seq = X_test[:, np.newaxis, :]\n",
        "y_train = y_train.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG4txz-ZqHPD",
        "outputId": "3737eebf-ab32-4947-b5dc-91fd82230b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "450/450 [==============================] - 25s 45ms/step - loss: 0.5729 - accuracy: 0.7082 - val_loss: 0.5503 - val_accuracy: 0.7226\n",
            "Epoch 2/15\n",
            "450/450 [==============================] - 20s 45ms/step - loss: 0.5599 - accuracy: 0.7173 - val_loss: 0.5523 - val_accuracy: 0.7233\n",
            "Epoch 3/15\n",
            "450/450 [==============================] - 20s 44ms/step - loss: 0.5547 - accuracy: 0.7196 - val_loss: 0.5531 - val_accuracy: 0.7251\n",
            "Epoch 4/15\n",
            "450/450 [==============================] - 20s 45ms/step - loss: 0.5542 - accuracy: 0.7212 - val_loss: 0.5405 - val_accuracy: 0.7303\n",
            "Epoch 5/15\n",
            "450/450 [==============================] - 19s 43ms/step - loss: 0.5534 - accuracy: 0.7229 - val_loss: 0.5467 - val_accuracy: 0.7235\n",
            "Epoch 6/15\n",
            "450/450 [==============================] - 20s 44ms/step - loss: 0.5524 - accuracy: 0.7230 - val_loss: 0.5416 - val_accuracy: 0.7287\n",
            "Epoch 7/15\n",
            "450/450 [==============================] - 19s 43ms/step - loss: 0.5522 - accuracy: 0.7227 - val_loss: 0.5437 - val_accuracy: 0.7269\n",
            "Epoch 8/15\n",
            "450/450 [==============================] - 19s 43ms/step - loss: 0.5520 - accuracy: 0.7226 - val_loss: 0.5410 - val_accuracy: 0.7302\n",
            "Epoch 9/15\n",
            "450/450 [==============================] - 19s 43ms/step - loss: 0.5514 - accuracy: 0.7224 - val_loss: 0.5413 - val_accuracy: 0.7278\n",
            "Epoch 10/15\n",
            "450/450 [==============================] - 20s 43ms/step - loss: 0.5501 - accuracy: 0.7231 - val_loss: 0.5423 - val_accuracy: 0.7285\n",
            "Epoch 11/15\n",
            "450/450 [==============================] - 18s 41ms/step - loss: 0.5495 - accuracy: 0.7243 - val_loss: 0.5419 - val_accuracy: 0.7286\n",
            "Epoch 12/15\n",
            "450/450 [==============================] - 20s 44ms/step - loss: 0.5496 - accuracy: 0.7227 - val_loss: 0.5393 - val_accuracy: 0.7310\n",
            "Epoch 13/15\n",
            "450/450 [==============================] - 20s 44ms/step - loss: 0.5483 - accuracy: 0.7249 - val_loss: 0.5457 - val_accuracy: 0.7278\n",
            "Epoch 14/15\n",
            "450/450 [==============================] - 19s 43ms/step - loss: 0.5489 - accuracy: 0.7231 - val_loss: 0.5427 - val_accuracy: 0.7286\n",
            "Epoch 15/15\n",
            "450/450 [==============================] - 20s 44ms/step - loss: 0.5482 - accuracy: 0.7245 - val_loss: 0.5484 - val_accuracy: 0.7241\n",
            "563/563 [==============================] - 5s 7ms/step\n",
            "MLP - Accuracy: 0.722.\n",
            "MLP - Precision: 0.722.\n",
            "MLP - Recall: 0.722.\n",
            "MLP - F1_Score: 0.722.\n",
            "\n",
            "Confusion Matrix: \n",
            " [[5226 2544]\n",
            " [2455 7775]]\n",
            "\n",
            " Clasification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.67      0.68      7770\n",
            "           1       0.75      0.76      0.76     10230\n",
            "\n",
            "    accuracy                           0.72     18000\n",
            "   macro avg       0.72      0.72      0.72     18000\n",
            "weighted avg       0.72      0.72      0.72     18000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Trial 0102 summary\n",
        "# Hyperparameters:\n",
        "# 64: 320\n",
        "# dropout_rate: 0.46869276466832943\n",
        "# num_additional_layers: 2\n",
        "# learning_rate: 0.01\n",
        "# optimizer: adam\n",
        "# loss_function: binary_crossentropy\n",
        "# tuner/epochs: 10\n",
        "# tuner/initial_epoch: 5\n",
        "# tuner/bracket: 4\n",
        "# tuner/round: 2\n",
        "# tuner/trial_id: 0090\n",
        "# Score: 0.7224823236465454\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(320, input_shape=(sequence_length, 19), return_sequences=True))\n",
        "model.add(LSTM(320, input_shape=(sequence_length, 19), return_sequences=True))\n",
        "model.add(Dropout(rate=0.46869276466832943))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "learning_rate = 0.01\n",
        "opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_seq, y_train, epochs=15, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test_seq)\n",
        "y_pred = y_pred.squeeze()\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# You can also use predict_proba to get probabilities instead of classes\n",
        "# y_pred_proba = model.predict_proba(X_test_seq)\n",
        "\n",
        "mlp_acc = accuracy_score(y_test, y_pred)\n",
        "mlp_pre = precision_score(y_test, y_pred, average='micro')\n",
        "mlp_recall = recall_score(y_test, y_pred, average='micro')\n",
        "mlp_f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(\"MLP - Accuracy: {:.3f}.\".format(mlp_acc))\n",
        "print(\"MLP - Precision: {:.3f}.\".format(mlp_pre))\n",
        "print(\"MLP - Recall: {:.3f}.\".format(mlp_recall))\n",
        "print(\"MLP - F1_Score: {:.3f}.\".format(mlp_f1))\n",
        "print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
        "print ('\\n Clasification Report:\\n', classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmRLxHaO_np4"
      },
      "source": [
        "HP Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "5x0nHJKg_nXw",
        "outputId": "4dd5dbe0-12c4-415e-8482-33336574daed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 113 Complete [00h 00m 27s]\n",
            "val_accuracy: 0.7063046097755432\n",
            "\n",
            "Best val_accuracy So Far: 0.7224823236465454\n",
            "Total elapsed time: 00h 48m 25s\n",
            "\n",
            "Search: Running Trial #114\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "448               |320               |64\n",
            "0.269             |0.46869           |dropout_rate\n",
            "2                 |2                 |num_additional_layers\n",
            "0.0001            |0.01              |learning_rate\n",
            "rmsprop           |adam              |optimizer\n",
            "binary_crossent...|binary_crossent...|loss_function\n",
            "5                 |10                |tuner/epochs\n",
            "0                 |5                 |tuner/initial_epoch\n",
            "3                 |4                 |tuner/bracket\n",
            "0                 |2                 |tuner/round\n",
            "\n",
            "Epoch 1/5\n",
            "280/351 [======================>.......] - ETA: 8s - loss: 0.6871 - accuracy: 0.5603"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-0ec14a6ae46e>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mval_loss_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStopTrainingOnHighValLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Get the best model from the search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "selected_layer_types = []\n",
        "# Define the function to build the LSTM model\n",
        "\n",
        "def build_lstm_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    lstm_units = hp.Int(64, min_value=32, max_value=512, step=32)\n",
        "\n",
        "    layer_types = [LSTM(units = lstm_units, input_shape=(1, 19), return_sequences=True),\n",
        "                   Dropout(rate=hp.Float('dropout_rate',min_value=0.2, max_value=0.5)),\n",
        "                   Dense(lstm_units, activation='relu')\n",
        "                  #  BatchNormalization()\n",
        "                   ]\n",
        "\n",
        "    # First LSTM layer\n",
        "    model.add(LSTM(units = lstm_units, input_shape=(1, 19), return_sequences=True))\n",
        "\n",
        "    # Hidden layer\n",
        "    temp_layer = []\n",
        "    num_additional_layers = hp.Int('num_additional_layers', min_value=2, max_value=4)\n",
        "    for i in range(num_additional_layers):\n",
        "        layer = random.choice(layer_types)\n",
        "        temp_layer.append(layer)\n",
        "        model.add(layer)\n",
        "    selected_layer_types.append(temp_layer)\n",
        "    # Last LSTM layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n",
        "    if optimizer == 'adam':\n",
        "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model with hyperparameters\n",
        "    model.compile(\n",
        "        loss=hp.Choice('loss_function', values=['binary_crossentropy']),\n",
        "        optimizer=opt,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialize the Keras Tuner and perform the search for best hyperparameters\n",
        "tuner = kt.Hyperband(\n",
        "    build_lstm_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=40,\n",
        "    factor=2,\n",
        "    directory='tuner_dir',\n",
        "    project_name='lstm_tuning',\n",
        "    overwrite = True\n",
        ")\n",
        "\n",
        "tuner.search(X_train_seq, y_train, epochs=50,batch_size=128, validation_split=0.3)\n",
        "\n",
        "# Get the best model from the search\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Display the layer names\n",
        "# for i, layer_type in enumerate(selected_layer_types):\n",
        "#     print(f'Trial {i + 1}: {layer_type}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZxKcZZXFpZ2"
      },
      "outputs": [],
      "source": [
        "# Display all trial's layers used\n",
        "for i, layer_type in enumerate(selected_layer_types):\n",
        "    print(f'Trial {i + 1}: {layer_type}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of n(10) best models"
      ],
      "metadata": {
        "id": "dmIeLm8KOn-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hstept1T5Ge4"
      },
      "outputs": [],
      "source": [
        "tuner.results_summary(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}